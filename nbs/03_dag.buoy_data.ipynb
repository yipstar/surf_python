{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp dag.buoy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-01-22 13:26:55,956] {settings.py:254} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=31291\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from huey.imports import *\n",
    "from huey.dag.airflow_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2019, 7, 24),\n",
    "    'email': ['heyhueyapp@gmail.com'],\n",
    "    'email_on_failure': True,\n",
    "    'email_on_retry': True,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    # 'queue': 'bash_queue',\n",
    "    # 'pool': 'backfill',\n",
    "    # 'priority_weight': 10,\n",
    "    # 'end_date': datetime(2016, 1, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# @hourly\n",
    "dag = DAG(\n",
    "    'huey_import_buoy_data', \\\n",
    "    default_args=default_args, \\\n",
    "    schedule_interval=\"0 * * * *\", \\\n",
    "    catchup=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DAG: huey_import_buoy_data>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import realtime wave data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from huey.data.importer.buoy_data import import_buoy_realtime_wave_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def run_import_buoy_realtime_wave_detail():\n",
    "    station_id = \"46025\"\n",
    "    import_buoy_realtime_wave_detail(station_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run_import_buoy_realtime_wave_detail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "t1 = PythonOperator(\n",
    "    task_id='import_buoy_realtime_wave_detail',\n",
    "    python_callable=run_import_buoy_realtime_wave_detail,\n",
    "    dag=dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.execute(context={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disable export until this bug is fixed\n",
    "\n",
    "slack_token = BaseHook.get_connection('slack').password\n",
    "t3 = SlackAPIPostOperator(\n",
    "    task_id='send_slack_success_alert',\n",
    "    token=slack_token,\n",
    "    text='Buoy Data Import Success.',\n",
    "    channel='#huey_data_import',\n",
    "    username='heyhueyapp',\n",
    "    dag=dag\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AirflowException",
     "evalue": "Slack API call failed (invalid_blocks_format)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAirflowException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-54004414aa71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/prophet/lib/python3.7/site-packages/airflow/operators/slack_operator.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_api_call_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mslack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSlackHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslack_conn_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslack_conn_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mslack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/prophet/lib/python3.7/site-packages/airflow/hooks/slack_hook.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, method, api_params)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ok'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Slack API call failed ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAirflowException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAirflowException\u001b[0m: Slack API call failed (invalid_blocks_format)"
     ]
    }
   ],
   "source": [
    "t3.execute(context={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.7'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import airflow\n",
    "airflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slack is broken in 1.10.7, fix is in 1.10.8.\n",
    "FIXME: upgrade to 1.10.8 when its out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-01-22 13:28:36,687] {settings.py:254} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=31483\n",
      "[2020-01-22 13:28:37,211] {__init__.py:51} INFO - Using executor SequentialExecutor\n",
      "[2020-01-22 13:28:37,211] {dagbag.py:403} INFO - Filling up the DagBag from /home/yipstar/airflow/dags\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "DAGS\n",
      "-------------------------------------------------------------------\n",
      "huey_import_buoy_data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!airflow list_dags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-01-22 13:28:47,325] {settings.py:254} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=31526\n",
      "[2020-01-22 13:28:47,826] {__init__.py:51} INFO - Using executor SequentialExecutor\n",
      "[2020-01-22 13:28:47,826] {dagbag.py:403} INFO - Filling up the DagBag from /home/yipstar/airflow/dags\n",
      "import_buoy_realtime_wave_detail\n"
     ]
    }
   ],
   "source": [
    "!airflow list_tasks huey_import_buoy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-01-21 16:19:56,735] {base_hook.py:84} INFO - Using connection to: id: huey_dev. Host: localhost, Port: None, Schema: huey_dev, Login: postgres, Password: XXXXXXXX, extra: None\n"
     ]
    }
   ],
   "source": [
    "t1.execute(context={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import_buoy_raw_spectral_wave_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from huey.data.importer.buoy_data import import_buoy_raw_spectral_wave_data\n",
    "\n",
    "def run_import_buoy_raw_spectral_wave_data():\n",
    "    station_id = \"46025\"\n",
    "    import_buoy_raw_spectral_wave_data(station_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-01-22 13:33:14,079] {base_hook.py:84} INFO - Using connection to: id: huey_dev. Host: localhost, Port: None, Schema: huey_dev, Login: postgres, Password: XXXXXXXX, extra: None\n",
      "observation for date: 2020-01-22 21:00:00+00:00 already present, skipping.\n",
      "import complete\n"
     ]
    }
   ],
   "source": [
    "data = run_import_buoy_raw_spectral_wave_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "t2 = PythonOperator(\n",
    "    task_id='import_buoy_raw_spectral_wave_data',\n",
    "    python_callable=run_import_buoy_raw_spectral_wave_data,\n",
    "    dag=dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation for date: 2020-01-22 21:00:00+00:00 already present, skipping.\n",
      "import complete\n"
     ]
    }
   ],
   "source": [
    "t2.execute(context={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.sql.ipynb.\n",
      "Converted 02_data.importer.buoy_data.ipynb.\n",
      "Converted 03_dag.buoy_data.ipynb.\n",
      "Converted 04_data.models.buoy.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huey.dag.buoy_data import run_import_buoy_realtime_wave_detail\n",
    "run_import_buoy_realtime_wave_detail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-01-22 13:33:55,859] {settings.py:254} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=31908\n",
      "[2020-01-22 13:33:56,440] {__init__.py:51} INFO - Using executor SequentialExecutor\n",
      "[2020-01-22 13:33:56,441] {dagbag.py:403} INFO - Filling up the DagBag from /home/yipstar/airflow/dags\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "DAGS\n",
      "-------------------------------------------------------------------\n",
      "huey_import_buoy_data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!airflow list_dags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-01-22 13:34:01,417] {settings.py:254} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=31947\n",
      "[2020-01-22 13:34:01,945] {__init__.py:51} INFO - Using executor SequentialExecutor\n",
      "[2020-01-22 13:34:01,945] {dagbag.py:403} INFO - Filling up the DagBag from /home/yipstar/airflow/dags\n",
      "import_buoy_raw_spectral_wave_data\n",
      "import_buoy_realtime_wave_detail\n"
     ]
    }
   ],
   "source": [
    "!airflow list_tasks huey_import_buoy_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
